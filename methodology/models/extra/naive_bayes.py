# AUTOGENERATED! DO NOT EDIT! File to edit: 02_naive_bayes.ipynb (unless otherwise specified).

__all__ = ['read_dir', 'load_data', 'train', 'test', 'run']


# Cell
import os
import sys
import time

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from tqdm import tqdm
import numpy as np


def read_dir(dir_path, label):
    """ Read all the files in the directory `dir_path` with the labels `label` and
        return a list of tuples (text, label)."""

    files = os.listdir(dir_path)
    data = []
    for file in tqdm(files, file=sys.stdout):
        with open(os.path.join(dir_path, file), 'r', encoding='utf-8') as f:
            data.append((f.read(), label))
    return data


def load_data(task):
    """ Load all the positive and negative examples for the training or test sets according to argument `task`,
        and return the shuffled data."""

    neg_dir_path = os.path.join('imdb_data', task, 'neg')
    pos_dir_path = os.path.join('imdb_data', task, 'pos')
    label = 0
    neg_data = read_dir(neg_dir_path, label)
    label = 1
    pos_data = read_dir(pos_dir_path, label)
    data = neg_data + pos_data
    np.random.shuffle(data)
    return data


def train(x_train, y_train, stop_words='english', ngram_range=(1, 1), max_features=None):
    """Create the BOW (i.e. word-count matrix) for the training set depending on input arguments
        whether or not consider `stop_words`, `ngram_range` such as words, bigrams, etc and
        `max_features`, which is the size of the vocabulary. Return the model and vectorizer objects."""

    vectorizer = CountVectorizer(input=x_train, stop_words=stop_words, ngram_range=ngram_range, min_df=10, max_df=0.9,
                                 max_features=max_features)
    print('Vectorizing training data i.e. Creating the word count matrix...', end=' ')
    x_train_vectorized = vectorizer.fit_transform(x_train)
    print('done!\n')
    print('Start training...')
    model = MultinomialNB()
    model.fit(x_train_vectorized, y_train)
    print('Training done!')
    print('Number of documents = {}  |  Number of features = {}'.format(x_train_vectorized.shape[0],
                                                                        x_train_vectorized.shape[1]))
    return model, vectorizer


def test(x_test, y_test, model):
    """Perform the prediction on the test set `x_test` and measures the accuracy based on actual labels `y_test`.
        Return the predictions and accuracy."""

    print('Start testing...')
    predictions = model.predict(x_test)
    accuracy = model.score(x_test, y_test)
    print('done!')
    return predictions, accuracy


def run(x_train, y_train, x_test, y_test, stop_words, ngram_range, max_features):
    """Vectorize the data, create the model, run the train and test and measure the accuracy considering the input
    arguments. """

    st_time = time.time()
    model, vectorizer = train(x_train, y_train, stop_words, ngram_range, max_features)
    en_time = time.time() - st_time
    print('Training time: {:.2f} s'.format(en_time))
    print()
    print('Vectorizing test data...', end=' ')
    x_test_vectorized = vectorizer.transform(x_test)
    print('done!')
    print('Test data shape = ', x_test_vectorized.shape)
    predictions, accuracy = test(x_test_vectorized, y_test, model)
    print('accuracy = {:.2f}'.format(accuracy))
    return predictions, accuracy
